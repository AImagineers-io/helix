# P29: LLM Provider Abstraction

## 1. Objective

**What**: Create a unified interface for LLM provider interactions. All providers implement the same contract for text generation and embeddings.

**Why**: The chatbot shouldn't care whether it's talking to OpenAI or Anthropic. This abstraction enables provider swapping, fallbacks, and mock providers for testing without API costs.

**Scope**:
- Included: Base provider interface, configuration models, provider registry, error types
- Excluded: Concrete provider implementations (P30, P31), fallback logic (P32)

**Dependencies**: None (foundation layer)

---

## 2. Implementation Tasks

### Task 29.1: Provider Interface

- [ ] Define abstract base class for LLM providers (2 files, ~80 LOC)
  - **Tests**: `tests/unit/test_llm_provider_interface.py`
    - `test_provider_interface_requires_generate()`
    - `test_provider_interface_requires_embed()`
    - `test_provider_config_validates_api_key()`
    - `test_provider_response_model_serializes()`
  - **Files**: `backend/llm/base.py`, `backend/llm/models.py`
  - **Implementation**:
    ```python
    from abc import ABC, abstractmethod
    from dataclasses import dataclass
    from typing import List, Optional

    @dataclass
    class LLMResponse:
        content: str
        model: str
        input_tokens: int
        output_tokens: int
        provider: str
        cached: bool = False

    @dataclass
    class EmbeddingResponse:
        vectors: List[List[float]]
        model: str
        input_tokens: int
        provider: str

    class LLMProvider(ABC):
        @abstractmethod
        async def generate(
            self,
            system_prompt: str,
            user_message: str,
            context: Optional[str] = None,
            max_tokens: int = 1024,
            temperature: float = 0.7,
        ) -> LLMResponse:
            """Generate text completion."""

        @abstractmethod
        async def embed(self, texts: List[str]) -> EmbeddingResponse:
            """Generate embeddings for texts."""

        @property
        @abstractmethod
        def supports_embeddings(self) -> bool:
            """Whether this provider supports embeddings."""
    ```

### Task 29.2: Provider Configuration

- [ ] Create provider configuration models (1 file, ~50 LOC)
  - **Tests**: `tests/unit/test_llm_config.py`
    - `test_config_loads_from_environment()`
    - `test_config_validates_required_fields()`
    - `test_config_has_sensible_defaults()`
    - `test_config_masks_api_key_in_repr()`
  - **Files**: `backend/llm/config.py`
  - **Implementation**:
    ```python
    @dataclass
    class ProviderConfig:
        api_key: str
        model: str
        timeout: float = 30.0
        max_retries: int = 3

        def __repr__(self) -> str:
            return f"ProviderConfig(model={self.model}, api_key=***)"

    @dataclass
    class OpenAIConfig(ProviderConfig):
        model: str = "gpt-4o-mini"
        embedding_model: str = "text-embedding-3-small"

    @dataclass
    class AnthropicConfig(ProviderConfig):
        model: str = "claude-3-haiku-20240307"
    ```

### Task 29.3: Provider Registry

- [ ] Create registry for provider lookup (1 file, ~40 LOC)
  - **Tests**: `tests/unit/test_provider_registry.py`
    - `test_registry_registers_provider()`
    - `test_registry_retrieves_by_name()`
    - `test_registry_raises_for_unknown_provider()`
    - `test_registry_lists_available_providers()`
  - **Files**: `backend/llm/registry.py`
  - **Implementation**:
    ```python
    class ProviderRegistry:
        _providers: Dict[str, Type[LLMProvider]] = {}

        @classmethod
        def register(cls, name: str, provider_class: Type[LLMProvider]):
            cls._providers[name] = provider_class

        @classmethod
        def get(cls, name: str) -> Type[LLMProvider]:
            if name not in cls._providers:
                raise UnknownProviderError(name)
            return cls._providers[name]

        @classmethod
        def available(cls) -> List[str]:
            return list(cls._providers.keys())
    ```

### Task 29.4: Provider Error Types

- [ ] Define provider-specific exceptions (1 file, ~30 LOC)
  - **Tests**: `tests/unit/test_llm_errors.py`
    - `test_rate_limit_error_includes_retry_after()`
    - `test_timeout_error_includes_duration()`
    - `test_auth_error_masks_api_key()`
  - **Files**: `backend/llm/errors.py`
  - **Implementation**:
    ```python
    class LLMError(Exception):
        """Base exception for LLM operations."""

    class RateLimitError(LLMError):
        def __init__(self, retry_after: Optional[float] = None):
            self.retry_after = retry_after

    class TimeoutError(LLMError):
        def __init__(self, timeout: float):
            self.timeout = timeout

    class AuthenticationError(LLMError):
        pass

    class UnknownProviderError(LLMError):
        pass
    ```

---

## 3. Success Criteria

- [ ] Abstract interface defines generate() and embed() contracts
- [ ] Provider configs load from environment variables
- [ ] Registry allows dynamic provider lookup
- [ ] Error types capture provider-specific failure modes
- [ ] All tests pass: `pytest tests/unit/test_llm_*.py tests/unit/test_provider_registry.py -v`
- [ ] No concrete implementations (those are P30, P31)
