# P41: Improvement Plan for P34.md

## What's Weak / Missing

- **Database migration not mentioned**: CostRecord model requires Alembic migration. No migration file specified.
- **No repository pattern**: Direct session usage in service. Harder to test, violates layer separation.
- **Pricing hardcoded**: PRICING dict embedded in code. Price updates require code deploy.
- **`_get_records_for_date` undefined**: Method called but not implemented.
- **`_aggregate_by_provider` undefined**: Method called but not implemented.
- **No monthly aggregation**: Only daily summary. Clients need monthly cost reports.
- **No retention/archival policy**: Cost records grow forever. No cleanup strategy.
- **Boolean import missing**: `Column(Boolean, ...)` used but `Boolean` not imported.
- **Cached responses tracked incorrectly**: Cached responses show original token counts, should show 0.

---

## Why This Matters

Missing migrations cause deployment failures. Undefined methods cause runtime errors. Hardcoded pricing becomes stale (providers change prices regularly). No retention means unbounded storage growth.

---

## Proposed Improvements

### Task 41.1: Create Database Migration

- [ ] Add Alembic migration for cost_records table (1 file, ~40 LOC)
  - **Tests**: `tests/integration/test_migrations.py`
    - `test_cost_records_migration_applies()`
    - `test_cost_records_migration_rollback()`
  - **Files**: `backend/alembic/versions/xxxx_add_cost_records.py`
  - **Implementation**:
    ```python
    def upgrade():
        op.create_table(
            'cost_records',
            sa.Column('id', postgresql.UUID(), primary_key=True),
            sa.Column('conversation_id', postgresql.UUID(), sa.ForeignKey('conversations.id'), nullable=True),
            sa.Column('provider', sa.String(50), nullable=False),
            sa.Column('model', sa.String(100), nullable=False),
            sa.Column('input_tokens', sa.Integer(), nullable=False),
            sa.Column('output_tokens', sa.Integer(), nullable=False),
            sa.Column('input_cost', sa.Float(), nullable=False),
            sa.Column('output_cost', sa.Float(), nullable=False),
            sa.Column('total_cost', sa.Float(), nullable=False),
            sa.Column('cached', sa.Boolean(), default=False),
            sa.Column('created_at', sa.DateTime(), default=sa.func.now()),
        )
        op.create_index('ix_cost_records_created_at', 'cost_records', ['created_at'])
        op.create_index('ix_cost_records_conversation_id', 'cost_records', ['conversation_id'])

    def downgrade():
        op.drop_table('cost_records')
    ```

### Task 41.2: Create Cost Repository

- [ ] Extract database operations to repository (1 file, ~60 LOC)
  - **Tests**: `tests/unit/test_cost_repository.py`
    - `test_create_cost_record()`
    - `test_get_records_by_date()`
    - `test_get_records_by_conversation()`
    - `test_aggregate_by_provider()`
  - **Files**: `backend/repositories/cost_repository.py`
  - **Implementation**:
    ```python
    class CostRepository:
        def __init__(self, session: AsyncSession):
            self.session = session

        async def create(self, record: CostRecord) -> CostRecord:
            self.session.add(record)
            await self.session.commit()
            await self.session.refresh(record)
            return record

        async def get_by_date_range(
            self,
            start_date: date,
            end_date: date,
        ) -> List[CostRecord]:
            stmt = select(CostRecord).where(
                CostRecord.created_at >= datetime.combine(start_date, time.min),
                CostRecord.created_at < datetime.combine(end_date + timedelta(days=1), time.min),
            )
            result = await self.session.execute(stmt)
            return result.scalars().all()

        async def aggregate_by_provider(self, start_date: date, end_date: date) -> Dict[str, float]:
            stmt = select(
                CostRecord.provider,
                func.sum(CostRecord.total_cost).label('total'),
            ).where(
                CostRecord.created_at >= datetime.combine(start_date, time.min),
                CostRecord.created_at < datetime.combine(end_date + timedelta(days=1), time.min),
            ).group_by(CostRecord.provider)
            result = await self.session.execute(stmt)
            return {row.provider: row.total for row in result}
    ```

### Task 41.3: Externalize Pricing Configuration

- [ ] Load pricing from config file or env (1 file modification, ~30 LOC)
  - **Tests**: `tests/unit/test_pricing_config.py`
    - `test_pricing_loads_from_yaml()`
    - `test_pricing_overridable_via_env()`
    - `test_pricing_fallback_to_defaults()`
  - **Files**: `backend/llm/pricing.py`
  - **Implementation**:
    ```python
    import yaml
    from pathlib import Path

    DEFAULT_PRICING = {
        "gpt-4o-mini": ModelPricing(0.15, 0.60),
        "gpt-4o": ModelPricing(2.50, 10.00),
        ...
    }

    def load_pricing() -> Dict[str, ModelPricing]:
        pricing = DEFAULT_PRICING.copy()

        # Try loading from config file
        config_path = Path(os.getenv("PRICING_CONFIG", "config/pricing.yaml"))
        if config_path.exists():
            with open(config_path) as f:
                custom = yaml.safe_load(f)
                for model, prices in custom.items():
                    pricing[model] = ModelPricing(
                        input_per_million=prices["input"],
                        output_per_million=prices["output"],
                    )

        return pricing

    PRICING = load_pricing()
    ```

### Task 41.4: Add Monthly Aggregation

- [ ] Add monthly cost summary method (1 file modification, ~25 LOC)
  - **Tests**: `tests/unit/test_cost_tracking.py`
    - `test_get_monthly_summary()`
    - `test_monthly_summary_groups_by_day()`
  - **Files**: `backend/llm/cost_tracking.py`
  - **Implementation**:
    ```python
    async def get_monthly_summary(self, year: int, month: int) -> Dict[str, Any]:
        start_date = date(year, month, 1)
        if month == 12:
            end_date = date(year + 1, 1, 1) - timedelta(days=1)
        else:
            end_date = date(year, month + 1, 1) - timedelta(days=1)

        records = await self.repository.get_by_date_range(start_date, end_date)
        by_day = defaultdict(float)
        for r in records:
            day = r.created_at.date().isoformat()
            by_day[day] += r.total_cost

        return {
            "year": year,
            "month": month,
            "total_cost": sum(r.total_cost for r in records),
            "total_requests": len(records),
            "by_day": dict(by_day),
            "by_provider": await self.repository.aggregate_by_provider(start_date, end_date),
        }
    ```

### Task 41.5: Add Retention Policy

- [ ] Implement cost record archival/cleanup (1 file, ~40 LOC)
  - **Tests**: `tests/unit/test_cost_retention.py`
    - `test_archives_old_records()`
    - `test_deletes_archived_after_period()`
    - `test_retention_respects_config()`
  - **Files**: `backend/llm/cost_retention.py`
  - **Implementation**:
    ```python
    @dataclass
    class RetentionConfig:
        archive_after_days: int = 90
        delete_after_days: int = 365

    class CostRetentionService:
        def __init__(self, repository: CostRepository, config: RetentionConfig):
            self.repository = repository
            self.config = config

        async def cleanup(self) -> Dict[str, int]:
            """Run retention cleanup. Call from scheduled job."""
            cutoff = date.today() - timedelta(days=self.config.delete_after_days)
            deleted = await self.repository.delete_before(cutoff)
            return {"deleted": deleted}
    ```

### Task 41.6: Fix Cached Response Cost Recording

- [ ] Record zero tokens for cached responses (1 file modification, ~10 LOC)
  - **Tests**: `tests/unit/test_cost_tracking.py`
    - `test_cached_response_records_zero_tokens()`
    - `test_cached_response_records_zero_cost()`
  - **Files**: `backend/llm/cost_tracking.py`
  - **Implementation**:
    ```python
    async def record(self, response: LLMResponse, conversation_id: Optional[UUID] = None) -> CostRecord:
        # Cached responses have no actual token cost
        if response.cached:
            input_tokens = 0
            output_tokens = 0
            input_cost = 0.0
            output_cost = 0.0
        else:
            input_tokens = response.input_tokens
            output_tokens = response.output_tokens
            input_cost, output_cost = calculate_cost(response.model, input_tokens, output_tokens)

        record = CostRecord(
            ...
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            input_cost=input_cost,
            output_cost=output_cost,
            total_cost=input_cost + output_cost,
            cached=response.cached,
        )
        ...
    ```

---

## Impact on Roadmap

- **Deployment**: Migration must run before code deploy.
- **Configuration**: New config file `config/pricing.yaml` or env `PRICING_CONFIG`.
- **Scheduled jobs**: Add cost retention cleanup to cron/scheduler.
- **P34 model**: Add `Boolean` import from sqlalchemy.
- **Dependencies**: Add `pyyaml` if not present.
