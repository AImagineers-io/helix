# P28e: Improvement Plan for P27e.md

## What's Weak / Missing

- **ResponseFormatConfig undefined**: Processor references this config but no definition provided.
- **ConversationService undefined**: ChatService depends on it but no definition or phase reference.
- **EventEmitter undefined**: PipelineObserver requires it but no specification of implementation.
- **Message splitting algorithm unspecified**: Messenger has 2000 char limit but no logic for where to split (word boundaries, sentence boundaries, mid-word?).
- **"Unsafe content" sanitization vague**: What specifically gets removed? XSS? Scripts? Null bytes?
- **Error response to user undefined**: When pipeline fails, what does the user see? No error response formatting.
- **Conversation history persistence missing**: ChatService "tracks conversation" but no storage mechanism shown.
- **Source formatting undefined**: API responses "include sources" but no format specified.
- **Observability events destination missing**: Events emitted but where do they go? SSE? Database? Logging?
- **No performance tests**: Integration tests exist but no load testing or latency benchmarks.
- **ResponseTranslationProcessor not included**: Should be in P27e but lives in P27b (per P28b fix).

---

## Why This Matters

Response formatting is the final user-facing step. Splitting messages mid-word makes responses unreadable. Undefined error responses mean users see stack traces or cryptic errors. Missing conversation persistence breaks multi-turn chat. Without observability destinations, events are emitted into void.

---

## Proposed Improvements

### Task 28e.1: Define ResponseFormatConfig

- [ ] Create response formatting configuration (1 file, ~30 LOC)
  - **Tests**: `tests/unit/test_response_format_config.py`
    - `test_loads_from_environment()`
    - `test_has_sensible_defaults()`
    - `test_validates_character_limits()`
  - **Files**: `backend/pipeline/config.py`
  - **Implementation**:
    ```python
    @dataclass
    class ResponseFormatConfig:
        max_response_length: int = 4000
        add_disclaimer: bool = False
        disclaimer_text: str = "This is an AI-generated response."
        sanitize_html: bool = True
        trim_whitespace: bool = True

        @classmethod
        def from_env(cls) -> "ResponseFormatConfig":
            ...
    ```

### Task 28e.2: Define ConversationService

- [ ] Create conversation storage and retrieval service (2 files, ~100 LOC)
  - **Tests**: `tests/unit/test_conversation_service.py`
    - `test_creates_new_conversation()`
    - `test_retrieves_conversation_history()`
    - `test_appends_message_to_conversation()`
    - `test_limits_history_size()`
    - `test_expires_old_conversations()`
  - **Files**: `backend/services/conversation_service.py`, `backend/models/conversation.py`
  - **Implementation**:
    ```python
    class Conversation(Base):
        id: UUID
        device_id: str
        platform: str
        messages: List[ConversationMessage]  # JSON column
        created_at: datetime
        updated_at: datetime

    class ConversationService:
        def __init__(self, session: Session, max_history: int = 20):
            ...
        async def get_or_create(self, device_id: str, platform: str) -> Conversation
        async def append_message(self, conversation_id: UUID, role: str, content: str)
        async def get_history(self, conversation_id: UUID) -> List[Message]
    ```

### Task 28e.3: Implement Smart Message Splitting

- [ ] Split long messages at sentence/word boundaries (1 file modification, ~40 LOC)
  - **Tests**: `tests/unit/test_channel_adapters.py`
    - `test_splits_at_sentence_boundary()`
    - `test_splits_at_word_boundary_if_no_sentence()`
    - `test_never_splits_mid_word()`
    - `test_preserves_url_integrity()`
    - `test_handles_code_blocks()`
  - **Files**: `backend/pipeline/adapters/channel.py`
  - **Implementation**:
    ```python
    class MessengerAdapter(ChannelAdapter):
        MAX_LENGTH = 2000

        def _split_message(self, text: str) -> List[str]:
            if len(text) <= self.MAX_LENGTH:
                return [text]

            chunks = []
            while text:
                if len(text) <= self.MAX_LENGTH:
                    chunks.append(text)
                    break

                # Find split point: sentence > paragraph > word > hard limit
                split_at = self._find_split_point(text, self.MAX_LENGTH)
                chunks.append(text[:split_at].strip())
                text = text[split_at:].strip()
            return chunks
    ```

### Task 28e.4: Define Output Sanitization

- [ ] Specify and implement content sanitization (1 file modification, ~30 LOC)
  - **Tests**: `tests/unit/test_response_formatting_processor.py`
    - `test_removes_script_tags()`
    - `test_removes_null_bytes()`
    - `test_escapes_html_entities()`
    - `test_preserves_safe_markdown()`
  - **Files**: `backend/pipeline/processors/response_formatting.py`
  - **Implementation**:
    ```python
    import bleach

    def _sanitize(self, text: str) -> str:
        # Remove null bytes and control characters
        text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f]', '', text)
        # Strip dangerous HTML (allow safe markdown-compatible tags)
        text = bleach.clean(text, tags=['b', 'i', 'code', 'pre'], strip=True)
        return text
    ```

### Task 28e.5: Add Error Response Formatting

- [ ] Define user-facing error responses (1 file, ~40 LOC)
  - **Tests**: `tests/unit/test_error_responses.py`
    - `test_pipeline_error_returns_friendly_message()`
    - `test_timeout_error_suggests_retry()`
    - `test_rate_limit_error_shows_wait_time()`
    - `test_error_response_respects_channel()`
  - **Files**: `backend/pipeline/error_responses.py`
  - **Implementation**:
    ```python
    class ErrorResponseFormatter:
        ERROR_MESSAGES = {
            "timeout": "I'm taking longer than expected. Please try again.",
            "rate_limited": "I'm receiving too many requests. Please wait a moment.",
            "internal": "Something went wrong on my end. Please try again later.",
        }

        def format(self, error: Exception, channel: str) -> ChannelResponse:
            message = self._get_message(error)
            adapter = ChannelAdapterFactory.get(channel)
            return adapter.format_error(message)
    ```

### Task 28e.6: Define Observability Event Destination

- [ ] Specify event storage and streaming (1 file modification, ~50 LOC)
  - **Tests**: `tests/unit/test_pipeline_observability.py`
    - `test_events_stored_in_database()`
    - `test_events_streamed_via_sse()`
    - `test_event_retention_policy()`
  - **Files**: `backend/pipeline/observability.py`
  - **Implementation**:
    ```python
    class PipelineObserver:
        def __init__(
            self,
            event_repository: ObservabilityEventRepository,
            sse_manager: Optional[SSEManager] = None,
        ):
            self._repo = event_repository
            self._sse = sse_manager

        def _emit(self, event: ObservabilityEvent) -> None:
            # Always persist
            self._repo.create(event)
            # Stream if SSE connected
            if self._sse:
                self._sse.broadcast(event.to_dict())
    ```

### Task 28e.7: Define Source Formatting for API

- [ ] Specify source attribution format (1 file modification, ~25 LOC)
  - **Tests**: `tests/unit/test_channel_adapters.py`
    - `test_api_response_includes_sources()`
    - `test_source_format_includes_qa_id_and_score()`
  - **Files**: `backend/pipeline/adapters/channel.py`
  - **Implementation**:
    ```python
    @dataclass
    class SourceAttribution:
        qa_pair_id: UUID
        question_preview: str  # First 100 chars
        similarity_score: float

    class APIAdapter(ChannelAdapter):
        def format(self, context: PipelineContext) -> ChannelResponse:
            sources = [
                SourceAttribution(
                    qa_pair_id=r.qa_pair.id,
                    question_preview=r.qa_pair.question[:100],
                    similarity_score=r.similarity_score
                )
                for r in context.retrieved_qa_pairs
            ]
            return ChannelResponse(
                messages=[context.final_response],
                metadata={"sources": [s.__dict__ for s in sources], ...}
            )
    ```

### Task 28e.8: Add ResponseTranslationProcessor

- [ ] Move from P27b and integrate into output phase (1 file, ~50 LOC)
  - **Tests**: `tests/unit/test_response_translation_processor.py`
    - (already defined in P27b, move here)
  - **Files**: `backend/pipeline/processors/response_translation.py`
  - **Pipeline order**: Runs after LLM generation, before response formatting

### Task 28e.9: Add Performance Benchmarks

- [ ] Create load tests for pipeline (1 file, ~60 LOC)
  - **Tests**: `tests/performance/test_pipeline_load.py`
    - `test_pipeline_handles_10_concurrent_requests()`
    - `test_p95_latency_under_2_seconds()`
    - `test_no_memory_leak_over_1000_requests()`
  - **Files**: `tests/performance/test_pipeline_load.py`
  - **Implementation**:
    ```python
    @pytest.mark.performance
    async def test_p95_latency_under_2_seconds(pipeline_factory, mock_services):
        latencies = []
        for _ in range(100):
            start = time.perf_counter()
            await pipeline.process(context)
            latencies.append(time.perf_counter() - start)

        p95 = sorted(latencies)[94]
        assert p95 < 2.0, f"P95 latency {p95:.2f}s exceeds 2s target"
    ```

---

## Impact on Roadmap

- **P27b**: ResponseTranslationProcessor removed, now in P27e.
- **Database migrations**: New Conversation model requires migration.
- **Dependencies**: Add `bleach` to requirements.txt for sanitization.
- **CI/CD**: Performance tests should run in separate pipeline (slower).
- **Frontend**: SSE connection for observability events needs client-side handling.
- **API documentation**: Source attribution format must be documented in OpenAPI spec.
