# P34: Cost Tracking

## 1. Objective

**What**: Record token usage and calculate costs for every LLM call. This data feeds the analytics dashboard and enables budget alerts.

**Why**: Clients need to understand their LLM spend. Runaway costs can happen (verbose prompts, no caching). Per-conversation cost helps optimize prompts. Budget alerts prevent bill shock.

**Scope**:
- Included: Cost record model, cost calculation service, daily aggregation, cost tracking decorator
- Excluded: Budget alerts (future), analytics dashboard (separate phase)

**Dependencies**: P33 (Response Cache)

---

## 2. Implementation Tasks

### Task 34.1: Cost Record Model

- [ ] Create cost record database model (1 file, ~40 LOC)
  - **Tests**: `tests/unit/test_cost_model.py`
    - `test_cost_record_stores_tokens()`
    - `test_cost_record_calculates_total_cost()`
    - `test_cost_record_tracks_provider()`
    - `test_cost_record_tracks_conversation()`
  - **Files**: `backend/models/cost_record.py`
  - **Implementation**:
    ```python
    from sqlalchemy import Column, Integer, Float, String, DateTime, ForeignKey
    from sqlalchemy.dialects.postgresql import UUID
    from backend.models.base import Base

    class CostRecord(Base):
        __tablename__ = "cost_records"

        id = Column(UUID, primary_key=True, default=uuid4)
        conversation_id = Column(UUID, ForeignKey("conversations.id"), nullable=True)
        provider = Column(String(50), nullable=False)
        model = Column(String(100), nullable=False)
        input_tokens = Column(Integer, nullable=False)
        output_tokens = Column(Integer, nullable=False)
        input_cost = Column(Float, nullable=False)
        output_cost = Column(Float, nullable=False)
        total_cost = Column(Float, nullable=False)
        cached = Column(Boolean, default=False)
        created_at = Column(DateTime, default=datetime.utcnow)
    ```

### Task 34.2: Pricing Configuration

- [ ] Create model pricing configuration (1 file, ~50 LOC)
  - **Tests**: `tests/unit/test_pricing_config.py`
    - `test_pricing_loads_from_config()`
    - `test_pricing_calculates_cost()`
    - `test_pricing_handles_unknown_model()`
    - `test_pricing_per_million_tokens()`
  - **Files**: `backend/llm/pricing.py`
  - **Implementation**:
    ```python
    @dataclass
    class ModelPricing:
        input_per_million: float
        output_per_million: float

    PRICING = {
        "gpt-4o-mini": ModelPricing(input_per_million=0.15, output_per_million=0.60),
        "gpt-4o": ModelPricing(input_per_million=2.50, output_per_million=10.00),
        "claude-3-haiku-20240307": ModelPricing(input_per_million=0.25, output_per_million=1.25),
        "claude-3-5-sonnet-20241022": ModelPricing(input_per_million=3.00, output_per_million=15.00),
        "text-embedding-3-small": ModelPricing(input_per_million=0.02, output_per_million=0.0),
    }

    def calculate_cost(model: str, input_tokens: int, output_tokens: int) -> Tuple[float, float]:
        pricing = PRICING.get(model)
        if not pricing:
            return 0.0, 0.0
        input_cost = (input_tokens / 1_000_000) * pricing.input_per_million
        output_cost = (output_tokens / 1_000_000) * pricing.output_per_million
        return input_cost, output_cost
    ```

### Task 34.3: Cost Tracking Service

- [ ] Create cost tracking service (1 file, ~60 LOC)
  - **Tests**: `tests/unit/test_cost_tracking.py`
    - `test_records_cost_for_llm_call()`
    - `test_records_zero_cost_for_cached()`
    - `test_aggregates_daily_costs()`
    - `test_aggregates_by_provider()`
    - `test_aggregates_by_conversation()`
  - **Files**: `backend/llm/cost_tracking.py`
  - **Implementation**:
    ```python
    class CostTracker:
        def __init__(self, session: Session):
            self.session = session

        async def record(
            self,
            response: LLMResponse,
            conversation_id: Optional[UUID] = None,
        ) -> CostRecord:
            input_cost, output_cost = calculate_cost(
                response.model, response.input_tokens, response.output_tokens
            )
            record = CostRecord(
                conversation_id=conversation_id,
                provider=response.provider,
                model=response.model,
                input_tokens=response.input_tokens,
                output_tokens=response.output_tokens,
                input_cost=input_cost,
                output_cost=output_cost,
                total_cost=input_cost + output_cost,
                cached=response.cached,
            )
            self.session.add(record)
            await self.session.commit()
            return record

        async def get_daily_summary(self, date: date) -> Dict[str, Any]:
            records = await self._get_records_for_date(date)
            return {
                "date": date.isoformat(),
                "total_cost": sum(r.total_cost for r in records),
                "total_requests": len(records),
                "cached_requests": sum(1 for r in records if r.cached),
                "by_provider": self._aggregate_by_provider(records),
            }
    ```

### Task 34.4: Integration with LLM Service

- [ ] Integrate cost tracking into LLM service (1 file modification, ~30 LOC)
  - **Tests**: `tests/unit/test_cached_llm_service.py`
    - `test_tracks_cost_after_generation()`
    - `test_tracks_zero_cost_for_cached()`
    - `test_tracks_conversation_id()`
  - **Files**: `backend/llm/service.py`
  - **Implementation**:
    ```python
    class LLMService:
        def __init__(
            self,
            orchestrator: FallbackOrchestrator,
            cache: ResponseCache,
            cost_tracker: CostTracker,
        ):
            self.orchestrator = orchestrator
            self.cache = cache
            self.cost_tracker = cost_tracker

        async def generate(
            self,
            system_prompt: str,
            user_message: str,
            context: Optional[str] = None,
            conversation_id: Optional[UUID] = None,
            **kwargs,
        ) -> LLMResponse:
            response = await self._generate_with_cache(...)
            # Track cost (cached responses have 0 token cost)
            await self.cost_tracker.record(response, conversation_id)
            return response
    ```

---

## 3. Success Criteria

- [ ] Cost records stored per LLM request
- [ ] Input/output tokens tracked separately
- [ ] Costs calculated per model pricing
- [ ] Cached responses tracked with zero cost
- [ ] Daily aggregation available
- [ ] Per-conversation costs trackable
- [ ] All tests pass: `pytest tests/unit/test_cost_*.py tests/unit/test_pricing_config.py -v`
