# P27c: Chat Pipeline - Moderation & Intent

## 1. Objective

**What**: Build moderation and intent classification processors for content filtering and message routing.

**Why**: Moderation filters inappropriate content before it reaches the LLM (saving costs, preventing misuse). Intent classification routes messages to appropriate handlers—greetings don't need RAG, escalation requests need human handoff.

**Scope**:
- Included: Moderation processor, intent classification processor
- Excluded: Pipeline architecture (P27a), language processors (P27b), RAG/LLM (P27d)

**Dependencies**: P27a (Pipeline Architecture & Context)

---

## 2. Implementation Tasks

### Task 27c.1: Create Content Moderation Service

- [ ] Build moderation rules engine (1 file, ~80 LOC)
  - **Tests**: `tests/unit/test_moderation_service.py`
    - `test_passes_clean_message()` - normal questions pass
    - `test_detects_profanity()` - profane words flagged
    - `test_detects_prompt_injection()` - injection attempts flagged
    - `test_detects_off_topic_spam()` - spam patterns flagged
    - `test_configurable_strictness()` - levels: low, medium, high
    - `test_returns_rejection_reason()` - explains why rejected
    - `test_case_insensitive_detection()` - bypasses not possible
  - **Files**: `backend/services/moderation_service.py`
  - **Implementation**:
    ```python
    class ModerationService:
        def __init__(self, strictness: str = "medium"):
            self._strictness = strictness
            self._profanity_list = self._load_profanity_list()
            self._injection_patterns = self._load_injection_patterns()

        def check(self, text: str) -> ModerationResult:
            """Check text for policy violations."""

    @dataclass
    class ModerationResult:
        is_flagged: bool
        reason: Optional[str]  # "profanity", "prompt_injection", "off_topic"
        confidence: float
        rejection_message: Optional[str]  # Polite user-facing message
    ```

### Task 27c.2: Create Moderation Processor

- [ ] Filter messages through moderation service (1 file, ~50 LOC)
  - **Tests**: `tests/unit/test_moderation_processor.py`
    - `test_passes_clean_message()` - continues pipeline
    - `test_flags_inappropriate_message()` - sets is_moderated=True
    - `test_sets_rejection_response()` - polite rejection in context
    - `test_logs_flagged_messages()` - audit trail
    - `test_processor_is_required()` - failure halts pipeline
  - **Files**: `backend/pipeline/processors/moderation.py`
  - **Implementation**:
    ```python
    class ModerationProcessor(Processor):
        name = "moderation"
        is_optional = False  # Required for safety

        def __init__(self, moderation_service: ModerationService):
            self._moderation_service = moderation_service

        async def process(self, context: PipelineContext) -> PipelineContext:
            """Check message against moderation rules."""
            # If flagged, set final_response to rejection message
            # and mark context so subsequent processors skip
    ```

### Task 27c.3: Create Intent Classification Service

- [ ] Classify message intent (1 file, ~100 LOC)
  - **Tests**: `tests/unit/test_intent_service.py`
    - `test_classifies_greeting()` - "Hello", "Hi there" → greeting
    - `test_classifies_farewell()` - "Goodbye", "Thanks, bye" → farewell
    - `test_classifies_question()` - "What is..." → question
    - `test_classifies_feedback()` - "That was helpful" → feedback
    - `test_classifies_escalation()` - "I want to speak to human" → escalation
    - `test_returns_confidence_score()` - 0.0 to 1.0
    - `test_low_confidence_defaults_to_question()` - safe default
    - `test_pattern_matching_for_common()` - no LLM for simple cases
  - **Files**: `backend/services/intent_service.py`
  - **Implementation**:
    ```python
    class IntentType(Enum):
        GREETING = "greeting"
        FAREWELL = "farewell"
        QUESTION = "question"
        FEEDBACK = "feedback"
        ESCALATION = "escalation"
        UNKNOWN = "unknown"

    class IntentService:
        def __init__(self, llm_client: Optional[LLMClient] = None):
            self._patterns = self._load_patterns()
            self._llm_client = llm_client

        def classify(self, text: str) -> IntentResult:
            """Classify intent using patterns first, LLM for ambiguous."""

    @dataclass
    class IntentResult:
        intent: IntentType
        confidence: float
        used_llm: bool
    ```

### Task 27c.4: Create Intent Classification Processor

- [ ] Route messages based on intent (1 file, ~60 LOC)
  - **Tests**: `tests/unit/test_intent_processor.py`
    - `test_stores_intent_in_context()` - intent accessible
    - `test_greeting_gets_canned_response()` - skip RAG
    - `test_farewell_gets_canned_response()` - skip RAG
    - `test_escalation_triggers_handoff()` - special handling
    - `test_question_continues_to_rag()` - normal flow
    - `test_processor_is_optional()` - failure defaults to question
  - **Files**: `backend/pipeline/processors/intent.py`
  - **Implementation**:
    ```python
    class IntentClassificationProcessor(Processor):
        name = "intent_classification"
        is_optional = True

        def __init__(self, intent_service: IntentService, canned_responses: dict):
            self._intent_service = intent_service
            self._canned_responses = canned_responses

        async def process(self, context: PipelineContext) -> PipelineContext:
            """Classify intent and route appropriately."""
            # For greeting/farewell: set final_response to canned
            # For escalation: set escalation flag
            # For question: continue to RAG
    ```

### Task 27c.5: Create Canned Response Configuration

- [ ] Configurable responses for intents (1 file, ~30 LOC)
  - **Tests**: `tests/unit/test_canned_responses.py`
    - `test_loads_from_config()` - reads from settings
    - `test_has_greeting_responses()` - multiple options
    - `test_has_farewell_responses()` - multiple options
    - `test_random_selection()` - variety in responses
  - **Files**: `backend/pipeline/processors/canned_responses.py`
  - **Implementation**:
    ```python
    @dataclass
    class CannedResponses:
        greetings: List[str]
        farewells: List[str]
        escalation: str  # "Let me connect you with a human..."

        @classmethod
        def from_config(cls) -> "CannedResponses":
            """Load from environment or defaults."""

        def get(self, intent: IntentType) -> Optional[str]:
            """Get random response for intent, or None."""
    ```

---

## 3. Success Criteria

- [ ] Moderation catches profanity, prompt injection, spam
- [ ] Flagged messages get polite rejection (not error)
- [ ] Flagged messages logged for review
- [ ] Intent classification handles common patterns without LLM
- [ ] Greetings/farewells get instant canned responses (no RAG)
- [ ] Escalation requests properly flagged for handoff
- [ ] Questions continue through normal RAG flow
- [ ] Configurable canned responses per deployment
- [ ] All tests pass: `pytest tests/unit/test_moderation_*.py tests/unit/test_intent_*.py tests/unit/test_canned_responses.py -v`
- [ ] Coverage ≥80% for moderation and intent processors
