# P69: Improvement Plan for P62.md

## Target Phase

P62: Batch Processing & Import Service

---

## What's Weak / Missing

- **No retry logic**: Transient DB connection errors or embedding API timeouts fail the entire batch permanently
- **Missing circuit breaker**: Repeated embedding service failures don't trigger fallback; keeps hammering failing service
- **No crash recovery**: If server restarts mid-import, job stuck in PROCESSING forever; no resumption mechanism
- **Batch size unjustified**: 50 is arbitrary; could be suboptimal for performance
- **No rate limiting for embedding API**: Burst of embed calls can exceed OpenAI rate limits
- **No memory management**: Processing 10k-row file loads all ParsedQA objects; no chunked reading
- **Missing job-to-pair traceability**: Created QA pairs don't reference their import job; can't audit which import created which content
- **Partial embedding failure unclear**: What happens if 3 of 50 embeddings fail? Pair created without embedding? Skipped?
- **No timeout per batch**: Single slow batch can block entire import indefinitely
- **Missing metrics**: No observability for batch processing performance, embedding latency

---

## Why This Matters

- **Data loss on transient failure**: Network blip during embedding causes import to fail; user must re-upload and re-process
- **Cost overrun risk**: No rate limiting can trigger 429s from OpenAI, causing cascade of failures and retries
- **Operational nightmare**: PROCESSING jobs never complete after crash; requires manual DB intervention
- **Debugging impossible**: Can't answer "which import added these bad QA pairs?" without traceability
- **Silent quality degradation**: QA pairs created without embeddings don't appear in RAG results; users confused why content not found

---

## Proposed Improvements

### 1. Add Retry with Exponential Backoff

```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

class BatchProcessor:
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=30),
        retry=retry_if_exception_type((SQLAlchemyError, ConnectionError)),
        before_sleep=lambda retry_state: logger.warning(
            f"Batch retry {retry_state.attempt_number} after {retry_state.outcome.exception()}"
        )
    )
    def _commit_batch(self, batch: List[QAPair]) -> None:
        """Commit batch with retry on transient errors."""
        self.session.add_all(batch)
        self.session.commit()
```

Add tests:
- `test_retries_on_transient_db_error()`
- `test_fails_after_max_retries()`

### 2. Implement Circuit Breaker for Embedding Service

```python
from circuitbreaker import circuit

class EmbeddingTrigger:
    def __init__(self, embedding_service: EmbeddingService):
        self.embedding_service = embedding_service
        self._failure_count = 0
        self._last_failure_time = None
        self._circuit_open = False
        self.failure_threshold = 5
        self.recovery_timeout = 60  # seconds

    async def trigger_for_pairs(self, pair_ids: List[UUID], ...):
        if self._circuit_open:
            if time.time() - self._last_failure_time < self.recovery_timeout:
                logger.warning("Circuit open, skipping embeddings")
                return 0  # Skip embeddings, return failure count
            self._circuit_open = False  # Try recovery

        try:
            result = await self._do_embeddings(pair_ids)
            self._failure_count = 0
            return result
        except EmbeddingServiceError as e:
            self._failure_count += 1
            self._last_failure_time = time.time()
            if self._failure_count >= self.failure_threshold:
                self._circuit_open = True
                logger.error("Circuit breaker opened for embedding service")
            raise
```

Add tests:
- `test_circuit_opens_after_threshold_failures()`
- `test_circuit_closes_after_recovery_timeout()`

### 3. Add Crash Recovery

```python
# In ImportService
async def recover_stale_jobs(self, timeout_minutes: int = 30) -> List[UUID]:
    """Find and mark stale PROCESSING jobs for recovery."""
    cutoff = datetime.utcnow() - timedelta(minutes=timeout_minutes)
    stale_jobs = self.job_repository.find_stale_processing(cutoff)

    recovered = []
    for job in stale_jobs:
        # Check last processed row, resume from there
        last_processed = job.processed_rows
        self.job_repository.update_status(job.id, ImportJobStatus.PENDING)
        logger.info(f"Recovered job {job.id}, will resume from row {last_processed}")
        recovered.append(job.id)

    return recovered

# In ImportJob model
class ImportJob(BaseModel):
    # Add checkpoint field
    checkpoint_data: Mapped[Optional[dict]] = mapped_column(JSON, nullable=True)
    # Stores: {"last_batch_start": 450, "completed_pair_ids": [...]}

# Schedule recovery check on startup
@app.on_event("startup")
async def startup_recovery():
    import_service = get_import_service()
    await import_service.recover_stale_jobs()
```

Add test: `test_stale_job_recovered_on_startup()`

### 4. Dynamic Batch Size Optimization

```python
class BatchProcessor:
    def __init__(self, session: Session, initial_batch_size: int = 50):
        self.session = session
        self.batch_size = initial_batch_size
        self.min_batch_size = 10
        self.max_batch_size = 200
        self._batch_times = []

    def _adjust_batch_size(self, batch_duration: float, batch_size: int):
        """Adjust batch size based on performance."""
        self._batch_times.append((batch_duration, batch_size))

        if len(self._batch_times) < 3:
            return

        # Calculate throughput (items/second) for recent batches
        recent = self._batch_times[-3:]
        throughput = sum(bs for _, bs in recent) / sum(t for t, _ in recent)

        # If batch is fast (<5s), try larger
        avg_time = sum(t for t, _ in recent) / len(recent)
        if avg_time < 5 and self.batch_size < self.max_batch_size:
            self.batch_size = min(int(self.batch_size * 1.5), self.max_batch_size)
        elif avg_time > 30 and self.batch_size > self.min_batch_size:
            self.batch_size = max(int(self.batch_size * 0.7), self.min_batch_size)
```

### 5. Add Rate Limiting for Embedding API

```python
from asyncio import Semaphore
import asyncio

class RateLimitedEmbeddingTrigger:
    def __init__(
        self,
        embedding_service: EmbeddingService,
        requests_per_minute: int = 60,
        max_concurrent: int = 5
    ):
        self.embedding_service = embedding_service
        self.semaphore = Semaphore(max_concurrent)
        self.rate_limiter = AsyncRateLimiter(requests_per_minute, 60)

    async def embed_batch(self, texts: List[str]) -> List[List[float]]:
        async with self.semaphore:
            await self.rate_limiter.acquire()
            return await self.embedding_service.embed_batch(texts)
```

### 6. Add Import Job Reference to QA Pairs

```python
# In QAPair model (migration required)
class QAPair(BaseModel):
    # Existing fields...
    import_job_id: Mapped[Optional[UUID]] = mapped_column(
        ForeignKey("import_job.id"),
        nullable=True
    )

# In QACreator
def create_from_parsed(self, parsed: ParsedQA, job_id: UUID = None) -> QAPair:
    qa_pair = QAPair(
        question=parsed.question,
        answer=parsed.answer,
        category=parsed.category,
        import_job_id=job_id,  # Track source
        # ...
    )
```

Add migration for `import_job_id` column with index.

### 7. Handle Partial Embedding Failures

```python
class EmbeddingTrigger:
    async def trigger_for_pairs(
        self,
        pair_ids: List[UUID],
        on_progress: Callable[[int, int], None] = None
    ) -> Tuple[int, List[UUID]]:
        """Returns (success_count, failed_pair_ids)."""
        success = 0
        failed = []

        for batch in chunks(pair_ids, 10):
            try:
                await self._embed_batch(batch)
                success += len(batch)
            except EmbeddingError as e:
                logger.error(f"Embedding failed for batch: {e}")
                failed.extend(batch)
                # Mark pairs as needing embedding retry
                for pair_id in batch:
                    self._mark_embedding_pending(pair_id)

            if on_progress:
                on_progress(success, len(pair_ids))

        return success, failed

# Add status to QAPair for embedding state
class QAPair(BaseModel):
    embedding_status: Mapped[str] = mapped_column(
        String(20),
        default="pending"  # pending, completed, failed
    )
```

### 8. Add Batch Timeout

```python
import asyncio

class BatchProcessor:
    def __init__(self, batch_timeout: int = 120):  # 2 minutes per batch
        self.batch_timeout = batch_timeout

    async def process_batch_with_timeout(self, batch: List[ParsedQA]) -> BatchResult:
        try:
            return await asyncio.wait_for(
                self._process_batch(batch),
                timeout=self.batch_timeout
            )
        except asyncio.TimeoutError:
            logger.error(f"Batch timed out after {self.batch_timeout}s")
            # Record timeout, continue with next batch
            return BatchResult(
                success_count=0,
                error_count=len(batch),
                errors=[{"type": "timeout", "message": "Batch processing timed out"}],
                created_ids=[]
            )
```

### 9. Add Metrics Collection

```python
from prometheus_client import Counter, Histogram, Gauge

IMPORT_BATCHES_TOTAL = Counter(
    'helix_import_batches_total',
    'Total import batches processed',
    ['status']  # success, error, timeout
)

IMPORT_BATCH_DURATION = Histogram(
    'helix_import_batch_duration_seconds',
    'Batch processing duration',
    buckets=[1, 5, 10, 30, 60, 120]
)

IMPORT_EMBEDDING_LATENCY = Histogram(
    'helix_import_embedding_latency_seconds',
    'Embedding API latency per batch'
)

IMPORT_ACTIVE_JOBS = Gauge(
    'helix_import_active_jobs',
    'Currently processing import jobs'
)
```

---

## Impact on Roadmap

| Affected Phase | Change |
|----------------|--------|
| P59 | Add `checkpoint_data` JSON field to ImportJob model |
| P59 | Add `import_job_id` FK to QAPair model |
| P60 | Parsers yield chunks for memory-efficient processing |
| P63 | Add `/qa/import/recover` admin endpoint |
| P64 | Show embedding status in import results |
| P65 | Add crash recovery integration tests |

---

## New Tasks for P62

- **Task 62.6**: Implement retry with exponential backoff for batch commits
- **Task 62.7**: Add circuit breaker for embedding service
- **Task 62.8**: Implement crash recovery with checkpoint resumption
- **Task 62.9**: Add rate limiting for embedding API calls
- **Task 62.10**: Add import_job_id traceability to QAPair
- **Task 62.11**: Handle partial embedding failures with retry queue
- **Task 62.12**: Add batch timeout handling
- **Task 62.13**: Instrument with Prometheus metrics

---

## Dependency Changes

Add to `backend/requirements.txt`:
```
tenacity>=8.2.0        # Retry logic
circuitbreaker>=2.0.0  # Circuit breaker (optional, can implement manually)
prometheus-client>=0.17.0  # Metrics
```
