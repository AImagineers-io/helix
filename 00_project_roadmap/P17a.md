# P17a: Embedding Service - Core

## 1. Objective

**What**: Build core embedding infrastructure: configuration, status tracking, OpenAI client, repository, and base service.

**Why**: Vector embeddings enable semantic similarity search. This phase establishes the foundation for generating and storing embeddings.

**Scope**:
- Included: Configuration module, embedding status enum, OpenAI client with retry, embedding repository, core embedding service
- Excluded: Batch processing (P17b), cost tracking (P17b), health monitoring (P17b)

**Dependencies**: P14 (Embedding model), P15 (QA service, transaction handling)

---

## 2. Implementation Tasks

### Task 17a.1: Create Configuration Module

- [ ] Centralize embedding configuration (1 file, ~50 LOC)
  - **Tests**: `tests/unit/test_embedding_config.py`
    - `test_loads_api_key_from_env()` - reads OPENAI_API_KEY
    - `test_loads_model_from_env()` - reads EMBEDDING_MODEL with default
    - `test_validates_api_key_present()` - raises if missing
    - `test_timeout_configurable()` - reads EMBEDDING_TIMEOUT_SECONDS
    - `test_retry_params_configurable()` - reads retry settings
  - **Files**: `backend/config/embedding.py`
  - **Implementation**:
    ```python
    @dataclass
    class EmbeddingConfig:
        api_key: str = field(default_factory=lambda: os.environ["OPENAI_API_KEY"])
        model: str = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
        timeout_seconds: int = int(os.getenv("EMBEDDING_TIMEOUT_SECONDS", "30"))
        max_retries: int = int(os.getenv("EMBEDDING_MAX_RETRIES", "3"))
        retry_base_delay: float = float(os.getenv("EMBEDDING_RETRY_DELAY", "1.0"))
        dimensions: int = 1536
    ```

### Task 17a.2: Add Embedding Status to Model

- [ ] Extend Embedding model with status tracking (2 files, ~40 LOC)
  - **Tests**: `tests/unit/test_models_embedding.py`
    - `test_embedding_status_pending()` - initial state
    - `test_embedding_status_processing()` - in-progress state
    - `test_embedding_status_completed()` - after success
    - `test_embedding_status_failed()` - after failure
    - `test_embedding_error_message_stored()` - failure reason captured
    - `test_embedding_retry_count_tracked()` - attempts recorded
  - **Files**: `backend/models/embedding.py`, `backend/models/enums.py`
  - **Implementation**:
    ```python
    class EmbeddingStatus(str, Enum):
        PENDING = "pending"
        PROCESSING = "processing"
        COMPLETED = "completed"
        FAILED = "failed"

    # Add to Embedding model:
    status: Mapped[EmbeddingStatus] = mapped_column(default=EmbeddingStatus.PENDING)
    error_message: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
    retry_count: Mapped[int] = mapped_column(default=0)
    ```

### Task 17a.3: Create OpenAI Embedding Client

- [ ] Create embedding client with timeout and retry (2 files, ~100 LOC)
  - **Tests**: `tests/unit/test_embedding_client.py`
    - `test_generate_embedding_single()` - returns 1536-dim vector
    - `test_generate_embedding_empty_text()` - raises ValueError
    - `test_generate_embedding_api_error()` - raises EmbeddingAPIError
    - `test_generate_embedding_rate_limit()` - raises RateLimitError
    - `test_timeout_raises_after_configured_seconds()` - doesn't hang
    - `test_retry_on_rate_limit()` - retries with backoff
    - `test_retry_stops_after_max_attempts()` - gives up eventually
    - `test_retry_backoff_exponential()` - delays increase
  - **Files**: `backend/clients/openai_embedding.py`, `backend/clients/__init__.py`
  - **Implementation**:
    ```python
    class OpenAIEmbeddingClient:
        def __init__(self, config: EmbeddingConfig):
            self.config = config

        async def generate(self, text: str) -> List[float]:
            """Generate embedding for single text with retry."""

        async def _generate_with_retry(self, texts: List[str]) -> List[List[float]]:
            for attempt in range(self.config.max_retries):
                try:
                    async with asyncio.timeout(self.config.timeout_seconds):
                        return await self._call_api(texts)
                except RateLimitError:
                    delay = self.config.retry_base_delay * (2 ** attempt)
                    await asyncio.sleep(delay)
            raise EmbeddingAPIError("Max retries exceeded")
    ```

### Task 17a.4: Create Embedding Repository

- [ ] Create data access for Embedding model (2 files, ~80 LOC)
  - **Tests**: `tests/unit/test_embedding_repository.py`
    - `test_create_embedding()` - inserts embedding with vector
    - `test_get_by_qa_pair_id()` - retrieves by FK
    - `test_get_by_qa_pair_id_not_found()` - returns None
    - `test_update_embedding()` - replaces vector
    - `test_delete_by_qa_pair_id()` - removes embedding
    - `test_list_by_status()` - filters by embedding status
    - `test_count_by_status()` - counts per status
  - **Files**: `backend/repositories/embedding_repository.py`
  - **Methods**:
    ```python
    def create(self, embedding: Embedding) -> Embedding
    def get_by_qa_pair_id(self, qa_pair_id: UUID) -> Optional[Embedding]
    def update(self, embedding: Embedding) -> Embedding
    def delete_by_qa_pair_id(self, qa_pair_id: UUID) -> bool
    def list_by_status(self, status: EmbeddingStatus, limit: int) -> List[Embedding]
    def count_by_status(self, status: EmbeddingStatus) -> int
    ```

### Task 17a.5: Create Embedding Service

- [ ] Create embedding service with status management (2 files, ~120 LOC)
  - **Tests**: `tests/unit/test_embedding_service.py`
    - `test_generate_for_qa_pair()` - creates embedding record
    - `test_generate_combines_question_answer()` - embeds "Q: {q}\nA: {a}"
    - `test_generate_updates_existing()` - replaces if exists
    - `test_generate_records_model_version()` - stores model name
    - `test_generate_sets_status_completed()` - status updated
    - `test_generate_handles_api_error()` - sets status FAILED
    - `test_has_embedding()` - checks existence
  - **Files**: `backend/services/embedding_service.py`, `backend/services/__init__.py`
  - **Implementation**:
    ```python
    class EmbeddingService:
        def __init__(self, session: Session, client: OpenAIEmbeddingClient, ...):
            ...

        async def generate_for_qa_pair(self, qa_pair: QAPair) -> Optional[Embedding]:
            """Generate and store embedding for a QA pair."""
            text = f"Q: {qa_pair.question}\nA: {qa_pair.answer}"
            # Set status PROCESSING, generate, set COMPLETED or FAILED

        async def has_embedding(self, qa_pair_id: UUID) -> bool
    ```

---

## 3. Success Criteria

- [ ] Configuration loads from environment variables
- [ ] Single embedding generates correctly (1536 dimensions)
- [ ] Timeout prevents hung API calls
- [ ] Retry logic handles rate limits with exponential backoff
- [ ] Embedding status tracked (PENDING → PROCESSING → COMPLETED/FAILED)
- [ ] All unit tests pass with mocked OpenAI client
- [ ] Coverage ≥80% for config/client/repository/service
