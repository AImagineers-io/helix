# P19a: Integration Tests - Infrastructure

## 1. Objective

**What**: Set up test infrastructure: requirements, factories, mocks, fixtures, and deterministic background tasks.

**Why**: Proper test infrastructure enables reliable, fast, and deterministic integration tests. Mocks prevent real API calls, fixtures ensure clean state.

**Scope**:
- Included: Test requirements, test factories, OpenAI mocks, PostgreSQL fixtures, deterministic background tasks
- Excluded: Actual integration tests (P19b), CI pipeline (P19b)

**Dependencies**: P13-P18 (all Knowledge Base components)

---

## 2. Implementation Tasks

### Task 19a.1: Add Test Requirements

- [ ] Define test dependencies (1 file, ~25 LOC)
  - **Files**: `backend/requirements-test.txt`
  - **Content**:
    ```
    pytest>=7.4.0
    pytest-asyncio>=0.21.0
    pytest-cov>=4.1.0
    pytest-timeout>=2.1.0
    httpx>=0.24.0
    testcontainers[postgres]>=3.7.0
    respx>=0.20.0
    factory-boy>=3.3.0
    faker>=19.0.0
    ```

### Task 19a.2: Create Test Factories

- [ ] Define reusable test data factories (1 file, ~100 LOC)
  - **Files**: `backend/tests/factories.py`
  - **Implementation**:
    ```python
    class QAPairFactory(factory.Factory):
        class Meta:
            model = QAPair

        id = factory.LazyFunction(uuid.uuid4)
        question = factory.Faker('sentence')
        answer = factory.Faker('paragraph')
        category = factory.Faker('word')
        tags = factory.LazyFunction(lambda: [fake.word() for _ in range(3)])
        status = QAStatus.DRAFT

    class EmbeddingFactory(factory.Factory):
        class Meta:
            model = Embedding

        id = factory.LazyFunction(uuid.uuid4)
        vector = factory.LazyFunction(lambda: [random.random() for _ in range(1536)])
        model_version = "text-embedding-3-small"
        status = EmbeddingStatus.COMPLETED
    ```

### Task 19a.3: Create OpenAI Mock Fixtures

- [ ] Mock OpenAI API for all tests (1 file, ~80 LOC)
  - **Files**: `backend/tests/mocks/openai_mock.py`
  - **Implementation**:
    ```python
    @pytest.fixture
    def mock_openai_embedding():
        """Mock OpenAI embedding API with deterministic responses."""
        with respx.mock:
            respx.post("https://api.openai.com/v1/embeddings").mock(
                return_value=httpx.Response(200, json={
                    "data": [{"embedding": [0.1] * 1536}],
                    "usage": {"total_tokens": 10}
                })
            )
            yield

    @pytest.fixture
    def mock_openai_embedding_failure():
        """Mock OpenAI API failure for error testing."""
        with respx.mock:
            respx.post("https://api.openai.com/v1/embeddings").mock(
                return_value=httpx.Response(429, json={"error": {"type": "rate_limit"}})
            )
            yield

    @pytest.fixture
    def mock_openai_embedding_timeout():
        """Mock OpenAI API timeout."""
        async def slow_response(*args, **kwargs):
            await asyncio.sleep(60)
        with respx.mock:
            respx.post("https://api.openai.com/v1/embeddings").mock(side_effect=slow_response)
            yield
    ```

### Task 19a.4: Create PostgreSQL Test Fixtures

- [ ] Create PostgreSQL fixtures with pgvector (2 files, ~120 LOC)
  - **Files**: `backend/tests/conftest.py`, `backend/tests/fixtures/database.py`
  - **Implementation**:
    ```python
    @pytest.fixture(scope="session")
    def postgres_container():
        """Start PostgreSQL with pgvector for integration tests."""
        with PostgresContainer("ankane/pgvector:latest") as postgres:
            yield postgres

    @pytest.fixture
    def pg_session(postgres_container):
        """PostgreSQL session with transaction rollback."""
        engine = create_engine(postgres_container.get_connection_url())
        Base.metadata.create_all(engine)
        with Session(engine) as session:
            yield session
            session.rollback()

    @pytest.fixture
    def populated_knowledge_base(pg_session, mock_openai_embedding):
        """10 QA pairs with embeddings for search tests."""
        qa_pairs = QAPairFactory.create_batch(10, status=QAStatus.ACTIVE)
        for qa in qa_pairs:
            pg_session.add(qa)
            embedding = EmbeddingFactory.create(qa_pair_id=qa.id)
            pg_session.add(embedding)
        pg_session.commit()
        return qa_pairs
    ```

### Task 19a.5: Implement Deterministic Background Tasks

- [ ] Replace async background with sync test mode (1 file, ~50 LOC)
  - **Tests**: `tests/unit/test_background_tasks.py`
    - `test_sync_mode_executes_immediately()` - no background delay
    - `test_async_mode_queues_task()` - production behavior
  - **Files**: `backend/services/background.py`
  - **Implementation**:
    ```python
    class BackgroundTaskRunner:
        def __init__(self, sync_mode: bool = False):
            self.sync_mode = sync_mode

        async def run(self, coro):
            if self.sync_mode:
                await coro
            else:
                asyncio.create_task(coro)

    @pytest.fixture
    def sync_background_tasks():
        """Background tasks execute synchronously in tests."""
        return BackgroundTaskRunner(sync_mode=True)
    ```

---

## 3. Success Criteria

- [ ] All test dependencies installable via requirements-test.txt
- [ ] Factories generate realistic test data
- [ ] OpenAI API fully mocked (no real API calls)
- [ ] PostgreSQL with pgvector available via testcontainers
- [ ] Background tasks execute synchronously in test mode
- [ ] Fixtures provide clean, isolated test state
- [ ] All infrastructure tests pass: `pytest tests/unit/test_background_tasks.py -v`
