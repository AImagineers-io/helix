# P28a: Improvement Plan for P27a.md

## What's Weak / Missing

- **No pipeline exception hierarchy**: Required processor failures have no defined exception types. Unclear what error surfaces to the user.
- **ProcessorTiming and ProcessorError dataclasses referenced but never defined**: Context uses these types without specifying their structure.
- **No timeout handling**: Individual processors can hang indefinitely. No mechanism to abort long-running processors.
- **No early abort mechanism**: After moderation blocks a message, all subsequent processors still run (checking `should_skip`). Wasteful.
- **Missing circuit breaker**: If a processor fails repeatedly, no protection against cascading failures.
- **"Processor registration" in scope but no task**: Scope mentions registration but no implementation task covers it.
- **Async concurrency undefined**: No decision on whether independent processors can run in parallel.
- **Factory dependency injection incomplete**: Factory needs LLM client, translation service, embedding service—none passed in or constructed.
- **Missing escalation_requested field in context**: P27c references escalation but context doesn't have this field.

---

## Why This Matters

Without exception handling, pipeline failures return unpredictable errors to users. Without timeouts, a hung translation API blocks the entire request. Without proper dependency injection in the factory, the pipeline cannot actually be instantiated. These are not edge cases—they are critical path failures.

---

## Proposed Improvements

### Task 28a.1: Define Pipeline Exception Hierarchy

- [ ] Create exception types for pipeline failures (1 file, ~40 LOC)
  - **Tests**: `tests/unit/test_pipeline_exceptions.py`
    - `test_processor_timeout_has_processor_name()`
    - `test_required_processor_failed_has_details()`
    - `test_pipeline_aborted_has_reason()`
  - **Files**: `backend/pipeline/exceptions.py`
  - **Implementation**:
    ```python
    class PipelineError(Exception): pass
    class ProcessorTimeoutError(PipelineError):
        def __init__(self, processor_name: str, timeout_seconds: float): ...
    class RequiredProcessorFailedError(PipelineError):
        def __init__(self, processor_name: str, original_error: Exception): ...
    class PipelineAbortedError(PipelineError):
        def __init__(self, reason: str, context: PipelineContext): ...
    ```

### Task 28a.2: Define Supporting Dataclasses

- [ ] Create ProcessorTiming and ProcessorError structures (1 file, ~30 LOC)
  - **Tests**: `tests/unit/test_pipeline_types.py`
    - `test_processor_timing_calculates_duration()`
    - `test_processor_error_captures_traceback()`
  - **Files**: `backend/pipeline/types.py`
  - **Implementation**:
    ```python
    @dataclass(frozen=True)
    class ProcessorTiming:
        processor_name: str
        started_at: datetime
        ended_at: datetime
        duration_ms: float
        was_skipped: bool

    @dataclass(frozen=True)
    class ProcessorError:
        processor_name: str
        error_type: str
        error_message: str
        traceback: Optional[str]
        is_recoverable: bool
    ```

### Task 28a.3: Add Timeout Handling to Orchestrator

- [ ] Wrap processor execution with configurable timeout (modify orchestrator, ~30 LOC)
  - **Tests**: `tests/unit/test_pipeline_orchestrator.py`
    - `test_processor_timeout_raises_exception()`
    - `test_optional_processor_timeout_continues()`
    - `test_timeout_configurable_per_processor()`
  - **Files**: `backend/pipeline/orchestrator.py`
  - **Config addition**:
    ```python
    processor_timeout_seconds: float = 30.0
    ```

### Task 28a.4: Add Pipeline Abort Mechanism

- [ ] Allow early termination without running remaining processors (1 file modification, ~20 LOC)
  - **Tests**: `tests/unit/test_pipeline_orchestrator.py`
    - `test_abort_flag_stops_pipeline()`
    - `test_aborted_context_returned_with_partial_results()`
  - **Files**: `backend/pipeline/context.py`, `backend/pipeline/orchestrator.py`
  - **Context field**:
    ```python
    should_abort: bool = False
    abort_reason: Optional[str] = None
    ```

### Task 28a.5: Add Missing Context Fields

- [ ] Add escalation and cost tracking fields to context (1 file modification, ~15 LOC)
  - **Tests**: `tests/unit/test_pipeline_context.py`
    - `test_context_has_escalation_requested()`
    - `test_context_has_total_cost()`
  - **Files**: `backend/pipeline/context.py`
  - **Fields**:
    ```python
    escalation_requested: bool = False
    total_cost_usd: float = 0.0
    token_usage: Optional[TokenUsage] = None
    ```

### Task 28a.6: Complete Factory Dependency Injection

- [ ] Factory accepts or creates all required services (1 file modification, ~40 LOC)
  - **Tests**: `tests/unit/test_pipeline_factory.py`
    - `test_factory_creates_llm_client()`
    - `test_factory_creates_translation_service()`
    - `test_factory_accepts_injected_services()`
  - **Files**: `backend/pipeline/factory.py`
  - **Implementation**:
    ```python
    class PipelineFactory:
        def __init__(
            self,
            session: Session,
            config: PipelineConfig,
            llm_client: Optional[LLMClient] = None,
            translation_service: Optional[TranslationService] = None,
            embedding_service: Optional[EmbeddingService] = None,
        ): ...
    ```

---

## Impact on Roadmap

- **P27b-P27d**: Can now rely on timeout protection and abort mechanism.
- **P27c**: Escalation flag properly defined in context.
- **P27e**: Integration tests can test abort and timeout scenarios.
- **Downstream API phases**: Have defined exceptions to catch and convert to HTTP responses.
