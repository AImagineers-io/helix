# P28b: Improvement Plan for P27b.md

## What's Weak / Missing

- **langdetect non-determinism unaddressed**: Library is known to produce inconsistent results for short texts. No seeding or mitigation strategy.
- **Google Translate API limits not handled**: API has per-request character limits (~128KB) and daily quotas. No chunking or quota tracking.
- **Unsupported language codes**: No fallback when detected language isn't supported by Google Translate.
- **Cache key strategy undefined**: Translation caching mentioned but no key format specified (collision risk).
- **No circuit breaker for translation API**: Repeated failures don't trigger any protective behavior.
- **ResponseTranslationProcessor sequencing wrong**: Defined in P27b but runs after LLM generation (P27d). Confuses build order.
- **Markdown preservation claim unsubstantiated**: No mechanism described for preserving markdown through translation.
- **Translation service async mismatch**: Service shown as sync but processor is async. Interface inconsistency.
- **No cost budget enforcement**: Character tracking exists but no mechanism to stop when budget exceeded.

---

## Why This Matters

Translation is a paid API with hard limits. Without quota handling, production traffic exhausts daily limits and all messages fail. Without circuit breaker, a Google outage cascades to complete service failure. langdetect inconsistency causes users to receive responses in wrong languages randomly.

---

## Proposed Improvements

### Task 28b.1: Fix langdetect Non-Determinism

- [ ] Seed langdetect and add multi-sample detection (1 file modification, ~25 LOC)
  - **Tests**: `tests/unit/test_language_detection_processor.py`
    - `test_detection_is_deterministic_for_same_input()`
    - `test_short_text_uses_multiple_samples()`
  - **Files**: `backend/pipeline/processors/language_detection.py`
  - **Implementation**:
    ```python
    from langdetect import DetectorFactory
    DetectorFactory.seed = 0  # Deterministic

    def _detect(self, text: str) -> Tuple[str, float]:
        if len(text) < 20:
            # Multiple detection passes, take majority
            results = [detect(text) for _ in range(3)]
            return Counter(results).most_common(1)[0][0], 0.6
    ```

### Task 28b.2: Add Translation API Resilience

- [ ] Circuit breaker and quota tracking for translation service (1 file modification, ~50 LOC)
  - **Tests**: `tests/unit/test_translation_service.py`
    - `test_circuit_breaker_opens_after_failures()`
    - `test_circuit_breaker_half_open_after_timeout()`
    - `test_quota_exceeded_raises_specific_error()`
    - `test_daily_quota_reset()`
  - **Files**: `backend/services/translation_service.py`
  - **Implementation**:
    ```python
    class TranslationService:
        def __init__(self, ..., daily_quota_chars: int = 500_000):
            self._circuit_breaker = CircuitBreaker(failure_threshold=5, recovery_timeout=60)
            self._daily_usage = 0
            self._quota_reset_time = None
    ```

### Task 28b.3: Handle Unsupported Languages

- [ ] Graceful fallback for unsupported language codes (1 file modification, ~20 LOC)
  - **Tests**: `tests/unit/test_translation_service.py`
    - `test_unsupported_language_falls_back_to_original()`
    - `test_logs_unsupported_language_warning()`
  - **Files**: `backend/services/translation_service.py`
  - **Implementation**:
    ```python
    SUPPORTED_LANGUAGES = {"en", "tl", "es", "fr", "de", "zh", "ja", "ko", ...}

    async def translate(self, text, source_lang, target_lang):
        if source_lang not in SUPPORTED_LANGUAGES:
            logger.warning(f"Unsupported source language: {source_lang}")
            return TranslationResult(text, text, source_lang, target_lang, False, 0)
    ```

### Task 28b.4: Define Cache Key Strategy

- [ ] Explicit cache key format with collision prevention (1 file modification, ~15 LOC)
  - **Tests**: `tests/unit/test_translation_service.py`
    - `test_cache_key_includes_all_params()`
    - `test_cache_key_handles_unicode()`
  - **Files**: `backend/services/translation_service.py`
  - **Implementation**:
    ```python
    def _cache_key(self, text: str, source: str, target: str) -> str:
        text_hash = hashlib.sha256(text.encode()).hexdigest()[:16]
        return f"translate:{source}:{target}:{text_hash}"
    ```

### Task 28b.5: Add Markdown-Safe Translation

- [ ] Protect markdown syntax during translation (1 file modification, ~40 LOC)
  - **Tests**: `tests/unit/test_translation_service.py`
    - `test_preserves_code_blocks()`
    - `test_preserves_links()`
    - `test_preserves_bold_italic()`
  - **Files**: `backend/services/translation_service.py`
  - **Implementation**:
    ```python
    def _protect_markdown(self, text: str) -> Tuple[str, List[str]]:
        """Replace markdown with placeholders, return mapping."""

    def _restore_markdown(self, text: str, placeholders: List[str]) -> str:
        """Restore markdown from placeholders."""
    ```

### Task 28b.6: Move ResponseTranslationProcessor to P27e

- [ ] Document that ResponseTranslationProcessor belongs in output phase
  - **Files**: Update P27b scope to exclude, P27e scope to include
  - **Rationale**: Response translation runs after LLM generation, logically belongs with response formatting

---

## Impact on Roadmap

- **P27a**: Factory must handle circuit breaker state.
- **P27d**: Can rely on consistent language detection for query translation.
- **P27e**: ResponseTranslationProcessor moved here; integration tests must cover markdown preservation.
- **Cost tracking**: Daily quota now enforced, prevents runaway API costs.
