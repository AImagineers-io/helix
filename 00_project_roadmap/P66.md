# P66: Improvement Plan for P59.md

## Target Phase

P59: Import Job Model & Foundation

---

## What's Weak / Missing

- **No cancellation flow defined**: `CANCELLED` status exists but no mechanism to transition to it or interrupt in-progress jobs
- **Missing concurrency control**: No optimistic locking or row-level locking for progress updates; concurrent writes can corrupt counters
- **Error JSON structure underspecified**: Errors stored as `List[dict]` with no schema; downstream consumers must guess structure
- **No retention policy**: ImportJob records accumulate indefinitely with no cleanup strategy
- **Missing created_by tracking**: No association between import job and the user/admin who initiated it
- **No job size estimation**: `total_rows` is set during processing, not upfront; UI cannot show "X of ?" until parsing completes
- **Index strategy incomplete**: Only `ix_import_job_status` defined; queries by `created_at` for history will table scan
- **Missing observability hooks**: No events emitted for job state transitions; breaks integration with existing ObservabilityEvent system
- **No idempotency key**: Re-uploading same file creates duplicate jobs with no deduplication

---

## Why This Matters

- **Data corruption risk**: Without concurrency control, parallel progress updates (from batches) can lose increments, resulting in inaccurate counts displayed to users
- **Operational burden**: No retention policy means import_job table grows unbounded; production queries slow over time
- **Debugging friction**: Unstructured error JSON forces developers to parse unknown formats when investigating failed imports
- **Observability gap**: No state transition events means the existing SSE stream and analytics cannot track imports
- **User confusion**: Without created_by, admins cannot audit who imported what content

---

## Proposed Improvements

### 1. Add Cancellation Support

```python
# In ImportJob model
cancelled_at: Mapped[Optional[datetime]] = mapped_column(nullable=True)
cancellation_reason: Mapped[Optional[str]] = mapped_column(String(255), nullable=True)

# In ImportJobRepository
def cancel(self, job_id: UUID, reason: str = None) -> bool:
    """Cancel job if still in PENDING or PROCESSING state."""
    job = self.session.query(ImportJob).with_for_update().get(job_id)
    if job.status not in (ImportJobStatus.PENDING, ImportJobStatus.PROCESSING):
        return False
    job.status = ImportJobStatus.CANCELLED
    job.cancelled_at = datetime.utcnow()
    job.cancellation_reason = reason
    return True
```

Add test: `test_cancel_job_transitions_status()`

### 2. Implement Optimistic Locking

```python
# In ImportJob model
version: Mapped[int] = mapped_column(default=1)

# In ImportJobRepository.update_progress()
def update_progress(self, job_id: UUID, processed: int, success: int, errors: int, expected_version: int):
    result = self.session.execute(
        update(ImportJob)
        .where(ImportJob.id == job_id, ImportJob.version == expected_version)
        .values(
            processed_rows=processed,
            success_count=success,
            error_count=errors,
            version=expected_version + 1
        )
    )
    if result.rowcount == 0:
        raise ConcurrentModificationError(job_id)
```

Add tests: `test_concurrent_update_raises_error()`, `test_version_increments_on_update()`

### 3. Define Error Schema

```python
@dataclass
class ImportErrorRecord:
    row: int
    field: Optional[str]
    error_type: str  # "validation", "parse", "duplicate", "system"
    message: str
    raw_data: Optional[str] = None  # Truncated to 500 chars
    timestamp: datetime = field(default_factory=datetime.utcnow)
```

Update Task 59.4 tests to validate error structure.

### 4. Add Retention and Cleanup

```python
# New repository method
def delete_old_jobs(self, days: int = 90, keep_failed: bool = True) -> int:
    """Delete completed jobs older than N days. Optionally preserve failed for audit."""
    cutoff = datetime.utcnow() - timedelta(days=days)
    query = delete(ImportJob).where(
        ImportJob.completed_at < cutoff,
        ImportJob.status == ImportJobStatus.COMPLETED if keep_failed else True
    )
    return self.session.execute(query).rowcount
```

Add migration task for scheduled cleanup job.

### 5. Add Missing Fields to Model

```python
class ImportJob(BaseModel):
    # Existing fields...

    # Add these:
    created_by: Mapped[Optional[str]] = mapped_column(String(255), nullable=True)  # User ID or API key name
    file_hash: Mapped[Optional[str]] = mapped_column(String(64), nullable=True)  # SHA256 for deduplication
    estimated_rows: Mapped[Optional[int]] = mapped_column(nullable=True)  # From quick file scan
```

### 6. Add Database Indexes

```python
# In migration
op.create_index("ix_import_job_created_at", "import_job", ["created_at"])
op.create_index("ix_import_job_created_by", "import_job", ["created_by"])
op.create_index("ix_import_job_file_hash", "import_job", ["file_hash"])
```

### 7. Emit Observability Events

```python
# In ImportJobRepository.update_status()
def update_status(self, job_id: UUID, status: ImportJobStatus):
    job = self.get_by_id(job_id)
    old_status = job.status
    job.status = status
    # ... existing logic ...

    emit_event(ObservabilityEvent(
        event_type="import_job_status_changed",
        payload={
            "job_id": str(job_id),
            "old_status": old_status.value,
            "new_status": status.value,
            "filename": job.filename,
        }
    ))
```

---

## Impact on Roadmap

| Affected Phase | Change |
|----------------|--------|
| P62 | Batch processor must pass version number for optimistic locking |
| P62 | Import service must check for cancellation between batches |
| P63 | Add `/qa/import/{job_id}/cancel` endpoint |
| P63 | Add `created_by` from authenticated user context |
| P64 | Add cancel button to progress component |
| P65 | Add concurrency and cancellation integration tests |

---

## New Tasks for P59

- **Task 59.6**: Implement optimistic locking with version field
- **Task 59.7**: Add cancellation support with cancel repository method
- **Task 59.8**: Define ImportErrorRecord schema with validation
- **Task 59.9**: Add retention cleanup method to repository
- **Task 59.10**: Emit observability events on status transitions
