# P32: Fallback Logic

## 1. Objective

**What**: Implement automatic failover from primary to fallback provider. If OpenAI times out or errors, try Anthropic. Multi-level fallback maximizes availability.

**Why**: Users expect the chatbot to work. A single provider failure shouldn't mean downtime. The fallback chain: Primary -> Fallback -> Cache -> Graceful degradation.

**Scope**:
- Included: Fallback orchestrator, timeout handling, failure detection, provider health tracking
- Excluded: Response caching (P33), cost tracking (P34)

**Dependencies**: P30 (OpenAI Provider), P31 (Anthropic Provider)

---

## 2. Implementation Tasks

### Task 32.1: Fallback Orchestrator

- [ ] Create fallback orchestrator service (1 file, ~100 LOC)
  - **Tests**: `tests/unit/test_fallback_orchestrator.py`
    - `test_uses_primary_provider_when_healthy()`
    - `test_falls_back_on_primary_timeout()`
    - `test_falls_back_on_primary_error()`
    - `test_returns_fallback_response_with_provider_tag()`
    - `test_raises_when_all_providers_fail()`
  - **Files**: `backend/llm/fallback.py`
  - **Implementation**:
    ```python
    @dataclass
    class FallbackConfig:
        primary_timeout: float = 10.0
        fallback_timeout: float = 15.0
        max_attempts_per_provider: int = 2

    class FallbackOrchestrator:
        def __init__(
            self,
            primary: LLMProvider,
            fallback: Optional[LLMProvider],
            config: FallbackConfig,
        ):
            self.primary = primary
            self.fallback = fallback
            self.config = config

        async def generate(
            self,
            system_prompt: str,
            user_message: str,
            context: Optional[str] = None,
            **kwargs,
        ) -> LLMResponse:
            # Try primary
            try:
                return await asyncio.wait_for(
                    self.primary.generate(system_prompt, user_message, context, **kwargs),
                    timeout=self.config.primary_timeout,
                )
            except (TimeoutError, LLMError) as primary_error:
                if not self.fallback:
                    raise

            # Try fallback
            try:
                return await asyncio.wait_for(
                    self.fallback.generate(system_prompt, user_message, context, **kwargs),
                    timeout=self.config.fallback_timeout,
                )
            except (TimeoutError, LLMError) as fallback_error:
                raise AllProvidersFailedError(primary_error, fallback_error)
    ```

### Task 32.2: Provider Health Tracking

- [ ] Track provider health for smart routing (1 file, ~60 LOC)
  - **Tests**: `tests/unit/test_provider_health.py`
    - `test_healthy_by_default()`
    - `test_marks_unhealthy_after_failures()`
    - `test_recovers_after_cooldown()`
    - `test_tracks_error_rate()`
    - `test_tracks_latency()`
  - **Files**: `backend/llm/health.py`
  - **Implementation**:
    ```python
    @dataclass
    class ProviderHealth:
        provider: str
        is_healthy: bool = True
        error_count: int = 0
        last_error: Optional[datetime] = None
        avg_latency_ms: float = 0.0
        unhealthy_until: Optional[datetime] = None

    class HealthTracker:
        def __init__(self, failure_threshold: int = 3, cooldown_seconds: float = 60):
            self._health: Dict[str, ProviderHealth] = {}
            self.failure_threshold = failure_threshold
            self.cooldown = cooldown_seconds

        def record_success(self, provider: str, latency_ms: float):
            health = self._get_health(provider)
            health.error_count = 0
            health.is_healthy = True
            health.avg_latency_ms = (health.avg_latency_ms + latency_ms) / 2

        def record_failure(self, provider: str, error: LLMError):
            health = self._get_health(provider)
            health.error_count += 1
            health.last_error = datetime.utcnow()
            if health.error_count >= self.failure_threshold:
                health.is_healthy = False
                health.unhealthy_until = datetime.utcnow() + timedelta(seconds=self.cooldown)

        def is_healthy(self, provider: str) -> bool:
            health = self._get_health(provider)
            if health.unhealthy_until and datetime.utcnow() > health.unhealthy_until:
                health.is_healthy = True
                health.error_count = 0
            return health.is_healthy
    ```

### Task 32.3: Graceful Degradation

- [ ] Return apologetic message when all providers fail (1 file modification, ~30 LOC)
  - **Tests**: `tests/unit/test_fallback_orchestrator.py`
    - `test_graceful_message_on_total_failure()`
    - `test_graceful_message_configurable()`
    - `test_logs_all_provider_failures()`
  - **Files**: `backend/llm/fallback.py`
  - **Implementation**:
    ```python
    @dataclass
    class FallbackConfig:
        graceful_message: str = "I'm having trouble processing your request right now. Please try again in a moment."

    class FallbackOrchestrator:
        async def generate_with_graceful_fallback(
            self,
            system_prompt: str,
            user_message: str,
            context: Optional[str] = None,
            **kwargs,
        ) -> LLMResponse:
            try:
                return await self.generate(system_prompt, user_message, context, **kwargs)
            except AllProvidersFailedError as e:
                logger.error(f"All providers failed: {e}")
                return LLMResponse(
                    content=self.config.graceful_message,
                    model="fallback",
                    input_tokens=0,
                    output_tokens=0,
                    provider="graceful_fallback",
                )
    ```

### Task 32.4: Embedding Fallback

- [ ] Handle embedding fallback (OpenAI only) (1 file modification, ~20 LOC)
  - **Tests**: `tests/unit/test_fallback_orchestrator.py`
    - `test_embed_uses_primary_only()`
    - `test_embed_raises_when_primary_fails()`
    - `test_embed_skips_fallback_without_embedding_support()`
  - **Files**: `backend/llm/fallback.py`
  - **Implementation**:
    ```python
    async def embed(self, texts: List[str]) -> EmbeddingResponse:
        # Embeddings only supported by OpenAI
        # No fallback since Anthropic doesn't support embeddings
        if not self.primary.supports_embeddings:
            raise NotSupportedError("Primary provider does not support embeddings")
        return await self.primary.embed(texts)
    ```

---

## 3. Success Criteria

- [ ] Primary provider used when healthy
- [ ] Automatic fallback on primary failure/timeout
- [ ] Provider health tracked with cooldown recovery
- [ ] Graceful degradation message when all fail
- [ ] Embeddings use primary only (no fallback)
- [ ] All failures logged for monitoring
- [ ] All tests pass: `pytest tests/unit/test_fallback_orchestrator.py tests/unit/test_provider_health.py -v`
